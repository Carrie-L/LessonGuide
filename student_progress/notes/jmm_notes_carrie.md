1 # JMM、Happens-Befo时间线：re、Volatile与Synchronized核心笔记
    2
    3 ## 1. 为什么需要Java内存模型 (JMM)？
    4
    5 *   **核心问题**:
      CPU为了速度引入了高速缓存，导致了多线程环境下的三个问题。
    6     *   **可见性**:
      [请用您自己的话描述，例如：一个线程改了东西，另一个线程看不见]
    7     *   **原子性**:
      [请用您自己的话描述，例如：一个转账操作，只做了一半]
    8     *   **有序性**:
      [请用您自己的话描述，例如：代码的顺序和执行的顺序可能不一样]
    9 *   **JMM的作用**:
      [请总结JMM的价值，例如：它是一套规则，用来屏蔽底层硬件差异，保证...]
   10
   11 ## 2. Happens-Before原则是什么？
   12
   13 *   **一句话理解**: [请用“接力赛”的比喻来描述]
   14 *   **核心保证**: 如果 A happens-before B，那么 JMM 保证...
   15 *   **我理解的关键规则**:
   16     *   **volatile规则**:
      对volatile变量的写，happens-before于后续对它的读。
   17     *   **锁规则**:
      对一个锁的解锁，happens-before于后续对同一个锁的加锁。
   18
   19 ## 3. Volatile vs Synchronized
   20
   21 ### `volatile` (公开的公告栏)
   22
   23 *   **解决什么问题**: [请填写：主要解决的是三大问题中的哪一个？]
   24 *   **如何解决**: [请结合“强制写回主存”和“强制从主存读”来描述]
   25 *   **不解决什么问题**: [请填写：它不能保证什么？比如 i++ 操作]
   26 *   **优点**: 轻量级，开销比synchronized小。
   27 *   **缺点**: 功能单一。
   28
   29 ### `synchronized` (带锁的会议室)
   30
   31 *   **解决什么问题**: [请填写：它解决了三大问题中的哪几个？]
   32 *   **如何解决**:
   33     *   **原子性**: [请结合“一次只进一个人”的比喻来描述]
   34     *   **可见性**: [请结合“进门前清空、出门前同步”的比喻来描述]
   35 *   **优点**: 功能强大，一步到位。
   36 *   **缺点**: [请填写：相比volatile，它的代价是什么？]

   ---

### JMM可见性问题

正常情况（使用volatile）下应该发生什么：

时间线：
0ms:    reader线程启动，进入while(!flag)循环 - - 每次都从主内存读取flag
1000ms: writer线程醒来，设置counter=42，flag=true - volatile写，立即同步到主内存
1001ms: reader线程应该看到flag=true，退出while循环
1003ms: reader线程的run()方法结束，线程自然死亡
3000ms: 主线程检查，reader.isAlive()应该返回false （线程已经结束）

可见性问题发生时：

时间线：
0ms:    reader线程启动，进入while(!flag)循环 - flag在reader缓存中是false
1000ms: writer线程设置counter=42，flag=true - 写入主内存，但reader缓存未更新
1001ms: ❌ reader线程的工作内存中flag仍然是false！ → 无限循环
3000ms: ❌ reader.isAlive()返回true （线程被困在while循环中）- 问题确认！

🌸 线程结束 = run()方法执行完毕

🌸 核心原理 ─────────────────────────────────────
  1. 偏向锁是JVM的"懒惰优化" - 如果只有一个线程使用锁，为什么要有开销？
  2. 第一次获取锁时，JVM在对象头中记录线程ID，后续获取几乎零开销
  3. 偏向锁的平均获锁时间通常在 1-5纳秒 范围内，这几乎是无开销的
  ─────────────────────────────────────────────────

 🌸 深度分析 ─────────────────────────────────────
  1. 轻量级锁使用 CAS (Compare-And-Swap) 操作来竞争锁，每次都要检查锁状态
  2. 线程切换导致的 CPU缓存失效 也会增加获锁开销
  3. 偏向锁只需要检查 "这还是我的锁吗？"，而轻量级锁需要 "我能获取这个锁吗？"
  ─────────────────────────────────────────────────

 正确的升级条件：
  - 偏向锁 → 轻量级锁：当第二个线程尝试获取偏向锁时
  - 轻量级锁 → 重量级锁：当CAS自旋失败次数超过阈值，或等待线程数过多时
  -  锁升级是单向的、不可逆的：偏向锁 → 轻量级锁 → 重量级锁。一旦升级为重量级锁，该对象永远保持重量级锁状态

 JVM的智能策略：
  1. 默认启用偏向锁 - 假设大多数锁是无竞争的
  2. 运行时收集统计 - 监控锁的竞争模式
  3. 自适应选择 - 根据历史行为选择最优锁实现

  🌸 现在请思考并回答：

  **为什么JVM不设计"锁降级"机制？比如当重量级锁的竞争减少时，为什么不能降级为轻量级锁？**

  这个问题的答案将帮你理解JVM设计的深层考虑！

   🌸 锁降级不可行的核心原因 ─────────────────────────────────────
  1. **对象头状态复杂性** - 一旦升级，对象头结构已经改变，降级需要大量状态重置
  2. **线程安全风险** - 降级过程本身需要同步，可能引入新的竞争和死锁
  3. **性能得不偿失** - 降级的检测和执行开销可能比保持重量级锁更昂贵
  ─────────────────────────────────────────────────

  #### 🌸 深度解析：为什么锁降级如此困难？

  1. 对象头状态问题

  偏向锁对象头：[线程ID | Epoch | 年龄 | 偏向锁标志]
  重量级锁对象头：[Monitor指针 | 锁标志]
  一旦变为重量级锁，对象头已经指向Monitor对象，无法简单回滚到之前的状态。

  2. 时机判断困难

  - 什么时候算"竞争减少"？1秒？10秒？
  - 如何预测未来不会再有激烈竞争？
  - 错误降级的代价很高 - 如果马上又有竞争，就要重新升级

  3. 实际收益有限

  重量级锁在无竞争时性能也不错：
  - 现代JVM的重量级锁已经高度优化
  - 大多数应用的锁竞争模式相对稳定
  - 预测错误的成本 > 可能的收益

  🌸 JVM的智慧选择

  JVM设计者选择了**"一次决策，长期有效"**的策略：
  - 快速响应竞争升级
  - 避免复杂的降级逻辑
  - 专注于优化每种锁的性能

  这就像交通规划：与其让高速公路时常变道，不如为每种交通模式建设专用通道。

  ### 🌸 Intermediate Level: 技术细节深度理解

  #### 1. 对象头中的偏向锁标记位

  **🌸 什么是Mark Word？**

  Mark Word 是Java对象头的重要组成部分：

  🌸 Java对象内存结构 ─────────────────────────────────────
  Java对象 = 对象头 + 实例数据 + 对齐填充
  对象头 = Mark Word + 类型指针(Klass Pointer)

  Mark Word (64位): 存储锁状态、GC信息、hashCode等元数据
  ─────────────────────────────────────────────────

  在Java对象中，每个对象都有一个**对象头(Object Header)**，它包含：

  🌸 对象头Mark Word结构 ─────────────────────────────────────
  偏向锁状态 (01)：[线程ID(23位) | Epoch(2位) | 年龄(4位) | 偏向锁(1位) | 锁标志(2位)]
  轻量级锁 (00)：[指向线程栈中Lock Record的指针(30位) | 锁标志(2位)]
  重量级锁 (10)：[指向重量级锁监视器的指针(30位) | 锁标志(2位)]
  ─────────────────────────────────────────────────

   #### 2. 偏向锁失效的3种情况

    情况1：多线程竞争

  ```java
    // 偏向锁失效示例
    Object lock = new Object();
    // Thread1获得偏向锁
    synchronized(lock) { /* Thread1的操作 */ }

    // Thread2尝试获取 -> 触发偏向锁撤销
    new Thread(() -> {
        synchronized(lock) { /* Thread2的操作 - 升级为轻量级锁 */ }
    }).start();
  ```

  情况2：延迟撤销机制

  - 批量重偏向：当某个类的对象偏向锁撤销次数达到阈值（默认20次）
  - 批量撤销：当撤销次数过多时（默认40次），JVM会对整个类禁用偏向锁

  情况3：显式调用

  ```java
  Object lock = new Object();
  synchronized(lock) {
      lock.hashCode(); // 调用hashCode()会撤销偏向锁！
  }
  // 因为hashCode需要存储在对象头中，与偏向锁信息冲突
  ```

 🌸 问题1：为什么调用hashCode()会失效偏向锁？

  因为：

  🌸 HashCode vs 偏向锁冲突 ─────────────────────────────────────
  偏向锁Mark Word: [ThreadID(23位) | Epoch(2位) | Age(4位) | 偏向标志 | 锁标志]
  HashCode需要空间: [HashCode(31位) | Age(4位) | 0 | 锁标志]
  冲突: 两者都需要使用Mark Word的前31位！
  ─────────────────────────────────────────────────

🌸问题2：为什么不直接跳到重量级锁？

  详细原因：
  - 轻量级锁成本：只需要CAS操作（几十纳秒）
  - 重量级锁成本：涉及系统调用（数千纳秒）
  - 适应性原理：大多数竞争是短暂的，轻量级锁足够应对

---

### CAS

分解一下 `compareAndSet(期望值A, 新值B)` 的内部逻辑：

   1. `比较 (Compare)`: 这一步是操作的核心。它只做一件事：
       * 拿线程期望的旧值 A (就是线程在计算前一刻读取到的值)
       * 去和内存中当前的值进行比较。

   2. `交换 (Swap)`:
       * 如果上面一步的比较结果是 true
         (意思是“内存中的值还停留在我上次读取时的A，没有被别人动过”)，那么就把新值 B 写入内存。
       * 如果比较结果是 false
         (意思是“内存中的值已经不是A了，在我思考的时候被别人改了”)，那么就什么也不做，交换失败。

---
核心规则：
   * 一个线程必须首先持有锁（进入卫生间），然后才能调用这个锁对象的 wait() 或
     notify() 方法（决定自己去等待，或者去唤醒别人）。
   * 如果一个线程连门都进不去，它就什么也做不了，只能在外面排队（BLOCKED）。

  这也就解释了为什么 wait() 和 notify() 方法必须在 `synchronized`
  代码块内部调用。如果你在 synchronized 外部调用它们，程序会直接抛出
  IllegalMonitorStateException 异常，就好像一个不在卫生间里的人，却想使用卫生间内
  部的设施一样，是完全不合逻辑的。
---

#### countdownlatch是什么？

相当于“倒数计时门闩”的角色。其核心作用是让一个或多个线程等待，直到在其他线程中执行的一系列操作全部完成。

`CountDownLatch` 位于 `java.util.concurrent` 包下，它的运作机制直观易懂：在初始化时，设定一个计数值。当线程完成其任务后，会调用 `countDown()` 方法，使计数值减一。而调用了 `await()` 方法的线程则会一直阻塞，直到计数值变为零，此时所有等待的线程将被唤醒并继续执行。

- **`await()`**: 该方法会使当前线程进入等待状态，直到计数值归零。此外，它还有一个重载版本 `await(long timeout, TimeUnit unit)`，允许设置一个最长等待时间，以避免无限期的阻塞。

需要注意的是，`CountDownLatch` 是一次性的，一旦计数值归零，它就不能被重置。

---

### 线程池核心概念

#### 线程池生命周期
1. RUNNING: 接受新任务，执行队列中的任务
2. ⏹ SHUTDOWN: 不接受新任务，执行完队列中的任务
3. STOP: 不接受新任务，不执行队列中的任务，中断进行中的任务
4. TERMINATED: 所有任务执行完毕，线程池彻底关闭

#### 线程池的4种常见类型

1. `FixedThreadPool` - 固定大小线程池
   特点: 固定线程数量，适合CPU密集型任务
   适用: 服务器程序，数据库连接池
   创建: Executors.newFixedThreadPool(nThreads)

2. `CachedThreadPool` - 缓存线程池
   特点: 动态调整线程数量，空闲线程自动回收
   适用: 短时异步任务，大量短暂的网络请求
   创建: Executors.newCachedThreadPool()

3. `SingleThreadExecutor` - 单线程线程池
   特点: 只有一个线程，保证任务按顺序执行
   适用: 需要保证顺序执行的任务，文件操作
   创建: Executors.newSingleThreadExecutor()

4. ⏰ `ScheduledThreadPool` - 定时任务线程池
   特点: 支持定时和周期性任务执行
   适用: 定时器，周期性任务，心跳检测
   创建: Executors.newScheduledThreadPool(nThreads)

#### ExecutorService核心API

**接口层次结构:**
Executor (最简单) → ExecutorService → ScheduledExecutorService
	     ↑                       ↑                        ↑
	  execute()         submit() + 定时任务

**核心方法对比:**
1. `execute`(Runnable) - 提交任务执行，无返回值
   特点: 无法获取执行结果，异常会终止线程
   适用: 火忘式任务，不关心结果

2. `submit`(Runnable/Callable) - 提交任务，返回Future
   特点: 可以获取执行结果，可以取消任务
   适用: 需要获取结果或取消的任务

3. `shutdown`() - 优雅关闭线程池
   特点: 不再接受新任务，执行完现有任务

4. `shutdownNow`() - 立即关闭线程池
   特点: 尝试中断所有正在执行的任务

#### Future接口详解

Future代表**异步计算**的结果:
Future<T> - 泛型，T是计算结果的类型

🌸 **核心方法:**
- `get()` - 获取结果，会阻塞直到计算完成
- `get(long, TimeUnit)` - 获取结果，带超时
- `isDone()` - 检查计算是否完成
- `cancel(boolean)` - 取消任务执行
- `isCancelled()` - 检查任务是否被取消

🌸 **Future的局限性:**
❌ 无法表示多个异步操作的结果
❌ 无法组合多个异步操作
❌ 无法处理异常（需要try-catch）
✅ 解决方案: `CompletableFuture` (Java 8+)

#### 拒绝策略详解

当线程池和队列都满了时的处理策略:

1. `AbortPolicy` (默认) - 抛出 RejectedExecutionException
   特点: 直接拒绝，抛出异常
   适用: 希望知道任务被拒绝的场景

2. `CallerRunsPolicy` - 由调用线程执行
   特点: 调用者线程执行该任务
   适用: 希望减缓任务提交速度的场景

3. `DiscardPolicy` - 直接丢弃任务
   特点: 静默丢弃，不通知任何人
   适用: 允许丢失一些任务的场景

4. `DiscardOldestPolicy` - 丢弃最老的任务
   特点: 丢弃队列中最老的任务，为新任务腾出空间
   适用: 希望保留最新任务的场景

### 线程池最佳实践示例

最佳实践原则:
1. 合理设置线程池大小
2. 正确处理异常
3. 监控线程池状态
4. 优雅关闭线程池
5. 避免线程池泄漏

#### 线程池大小设置建议

当我们在程序里使用 **线程池** 时，需要决定线程池里要开多少线程。如果线程数设置得太少，CPU 没被充分利用；如果线程数设置得太多，线程上下文切换（切来切去）会消耗很多性能。

所以要根据**任务类型**来设置线程数。

- **CPU密集型**: Runtime.getRuntime().availableProcessors()
- **IO密集型**: Runtime.getRuntime().availableProcessors() * 2
- **混合型**: 需要根据实际情况调整

##### CPU 密集型任务（CPU-bound）

这种任务主要消耗的是 `CPU` 的算力（如：运算逻辑、数学计算、加解密、压缩、图像处理、机器学习计算等）。

**特点：**任务几乎不需要等待 `IO`（网络、磁盘、数据库），一直在烧CPU。

**线程数推荐：**一般设为 `CPU核心数 + 1 ` ，+1 是为了如果有线程因为偶尔GC或其它原因停顿，额外的一个线程可以补上。

##### IO 密集型任务（IO-bound）

这种任务的主要瓶颈是 **IO (磁盘读写、网络请求、数据库访问)** 。

**特点：**线程经常处于等待状态，CPU并没有被充分利用。

**线程数推荐：**一般设为 `CPU核心数 * 2` 或更多。因为大部分线程都在等待IO，不会同时消耗CPU，开多线程能在等待期间让别的线程继续工作。

##### 怎么判断一个任务是 CPU 密集还是 IO 密集？

- 主要在做计算（CPU 占用率高，IO 不多）-> CPU 密集型
- 主要在等待外部资源（网络、文件、数据库） -> IO 密集型

### 安卓线程池设计

#### 计算密集 Dispatchers.Default

（算法、图片/视频编解码、加密、Diff 计算等）
并发度 = `CPU核数(cores)` ～ `cores + 1`

`Dispatchers.Default`（Kotlin 已按核数做了良好限流）

如需更严格控制并发度：

```kotlin
val cpuDispatcher = Dispatchers.Default.limitedParallelism(cores) // cores~cores+1
```

#### IO 密集 Dispatchers.IO

（网络/磁盘/数据库等阻塞明显）

并发度 ≈ `cores × 2` ～ `cores × 4`，但**加上硬上限**（建议 32~64 之间），避免线程风暴。

`Dispatchers.IO` 是可扩张线程池。

如果需要再套一层**限流**：

```kotlin
val ioDispatcher = Dispatchers.IO.limitedParallelism(minOf(cores * 2, 32))
```

#### 混合型（既算又等）

并发度 ≈ `cores × (1 + 等待/计算 比例)`，再**封顶 16~32**。

短小可并行任务批处理：

```kotlin
coroutineScope {
    withContext(cpuDispatcher) {
        items.chunked(64).map { chunk ->
            async { processChunk(chunk) }
        }.awaitAll()
    }
}
```

**UI 相关**：严格用主线程 + `Handler`/`Dispatchers.Main`，重活丢后台。

获取核数：
```kotlin
val cores = Runtime.getRuntime().availableProcessors() // （包含大小核与超线程）
```

#### 影响因素

1. **大小核（big.LITTLE）**：`availableProcessors()`给的是总逻辑核数；在弱核/降频下，多开线程并不会更快，**所以要设上限**。
2. **电量/温控**：过多后台线程会触发温控降频 → 反而变慢、还更耗电。
3. **系统线程竞争**：Binder 线程池、渲染/音视频/GC 线程都在同一台设备上，别把机器“吃满”。
4. **Android 后台限制**：Doze / App Standby / 前后台切换会影响调度，IO 更不稳定 → IO 池更应“**宽而有上限**”。

### 背压是什么？

背压 (Backpressure) 是并发编程、消息队列、响应式编程里的一个核心概念。

当**生产速度**（产生任务/数据的速度）远大于**消费速度**（处理任务/数据的速度）时，系统为了避免崩溃或资源耗尽，需要采取的`限制和反馈机制`。

打个比方：

- 水龙头接水（生产者 = 水龙头出水速度；消费者 = 杯子容量）
- 如果水龙头出水速度太快，杯子来不及接 ——> 水溢出来
- 解决：要么关小水龙头（减慢生产速度），要么换个大水桶（缓存/队列），要么快速把杯子里的水倒掉（丢弃策略）

![[Pasted image 20250828183152.png]]

这个调节过程就是**背压**。它的本质是让系统的 **生产速度** 和 **消费能力** 匹配，避免过载。

### 背压的基本流程（逻辑循环）

1. **生产（Produce）**
    - 生产者源源不断地产生数据/任务。
    - 速度可能远大于消费者处理能力。
    - 例：点击按钮每次都发网络请求、传感器高频采样。

2. **缓存/队列（Buffer/Queue）**
    - 系统用缓冲区或队列暂存数据，起到“水库”的作用。
    - 队列满了 → 出现背压点。

3. **检测过载（Detect Overload）**
    - 队列/缓冲区是否溢出？
    - 消费者处理延迟是否过长？
    - CPU、内存、带宽等资源是否接近极限？
    - 一旦检测到“消费跟不上生产”，触发背压逻辑。

4. **采取策略（Apply Strategy）**
    常见的背压策略：
    - **限速**：减慢生产速度（Rate Limit）。
    - **丢弃**：丢弃新任务或旧任务（Discard、Drop）。
    - **回退**：把任务交给调用方执行（CallerRunsPolicy）。
    - **合并**：把多个任务合并为一个（例如 UI 的 `throttle/debounce`）。
    - **扩容**：短期允许更多缓存/线程（有上限）。

5. **反馈（Feedback）**
    - 告诉生产者：“我现在能接收的量是多少”。
    - 如果是 Pull 模型（例如 **Reactive Streams**）：消费者显式 `request(n)` 来表示需求量。
    - 如果是 Push 模型：生产者根据反馈调整速度。

然后回到步骤 1，形成一个动态调节闭环。

```css
生产者（持续产出）
       ↓
   [缓冲区/队列]
       ↓ （检测是否满/过载？）
   ┌───────────────┐
   │               │
   否 → 继续消费    是 → 触发背压策略
                   │
        ┌──────────┴─────────┐
        ↓                    ↓
   限速/丢弃/合并        调整生产速率
        ↓                    ↓
      消费者 ←←←←←←←←←←←←←←←←←
```

![[Pasted image 20250828185046.png]]

### 在 Android 场景下的背压逻辑例子

#### 例 1：RxJava Flowable（响应式流）

- **生产者**：传感器每 1ms 发一次数据。
- **消费者**：处理逻辑只能 100ms 处理一次。
- **背压点**：`onBackpressureDrop()` → 丢弃多余事件，只保留最新。
- **逻辑**：消费者发出 `request(1)`，生产者只交付一个，其他丢掉。

#### 例 2：线程池

- **生产者**：主线程不断 `submit()` 任务。
- **队列**：`BlockingQueue` 缓冲。
- **背压点**：队列满了 → 执行拒绝策略。
- **策略**：
    - `AbortPolicy` → 直接抛异常。
    - `DiscardPolicy` → 悄悄丢弃任务。
    - `CallerRunsPolicy` → 让调用线程自己执行（自然限速）。

#### 例 3：UI 点击事件

- **生产者**：用户快速连点按钮（100 次/秒）。
- **消费者**：网络请求/数据库写入。
- **背压点**：`throttleFirst(1s)` → 只允许 1 秒钟内触发一次事件。
- **逻辑**：过多的点击被合并/丢弃。

![[backpressue logic map.svg]]

### 为什么要关心背压？

在并发系统、响应式编程、消息队列、网络传输中，生产者经常比消费者快。

如果没有控制，会导致OOM、高延迟、CPU 抖动甚至系统崩溃。

简单来说，背压就是系统在过载时的自我保护机制，让生产速度和消费能力匹配。

在Android 并发编程中，背压无处不在。

- **线程池**：队列满了，执行 `CallerRunsPolicy` → 背压。
- **RxJava**：`onBackpressureBuffer`、`onBackpressureDrop`。
- **UI 点击事件**：`throttleFirst`、`debounce`，防止短时间内点击过多。
- **网络请求**：限制并发数（Semaphore、OkHttp Dispatcher）。

🌸 学习建议:
1. 先理解概念，再看代码
2. 从简单示例开始
3. 运行代码观察行为
4. 尝试修改参数
5. 记录你的发现
